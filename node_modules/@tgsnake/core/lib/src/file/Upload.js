"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.upload = void 0;
const platform_node_js_1 = require("../platform.node.js");
const Queue_js_1 = require("../Queue.js");
const index_js_1 = require("../errors/index.js");
const index_js_2 = require("../session/index.js");
const index_js_3 = require("../raw/index.js");
const Logger_js_1 = require("../Logger.js");
async function upload(client, source, fileName, fileId, filePart = 0, progress) {
    const [, release] = await client._saveFileSemaphore.acquire();
    try {
        const queue = new Queue_js_1.Queue(1);
        const partSize = 512 * 1024;
        const premium = client._me?.users.find((user) => user.id === client._me?.fullUser.id)
            ? true
            : false;
        const fileSizeLimitMiB = premium ? 4000 : 2000;
        const fileSize = source.byteLength;
        if (fileSize === 0) {
            throw new index_js_1.FileErrors.FileUploadZero();
        }
        if (fileSize > fileSizeLimitMiB * 1024 * 1024) {
            throw new index_js_1.FileErrors.FileUploadBigger(fileSizeLimitMiB * 1024 * 1024, fileSize);
        }
        async function worker(session, index) {
            Logger_js_1.Logger.debug(`[137] Worker ${index} running`);
            while (true) {
                Logger_js_1.Logger.debug(`[138] Worker ${index} getting the queue`);
                let data = await queue.get();
                Logger_js_1.Logger.debug(`[139] Worker ${index} successfully getting the queue`);
                if (data === null) {
                    Logger_js_1.Logger.debug(`[140] Worker ${index} finished`);
                    return;
                }
                try {
                    Logger_js_1.Logger.debug(`[141] Worker ${index} sending data from queue`);
                    await session.invoke(data);
                }
                catch (error) {
                    Logger_js_1.Logger.error(`[135] Error when uploading file:`, error);
                }
            }
        }
        const fileTotalParts = Math.ceil(fileSize / partSize);
        const isBig = fileSize > 10 * 1024 * 1024;
        const workersAmount = isBig ? 4 : 1;
        const isMissingPart = fileId !== undefined;
        fileId = fileId || platform_node_js_1.Buffer.from(platform_node_js_1.crypto.randomBytes(8)).readBigInt64LE();
        const file = new index_js_3.BytesIO(source);
        const md5 = !isBig && !isMissingPart ? platform_node_js_1.crypto.createHash('md5').update(source).digest('hex') : '';
        const session = new index_js_2.Session(client, client._storage.dcId, client._storage.authKey, client._storage.testMode, client._proxy, true);
        const workers = Array(workersAmount)
            .fill(null)
            .map((_, i) => (() => worker(session, i + 1))());
        try {
            await session.start();
            file.seek(partSize * filePart);
            while (true) {
                let chunk = file.read(partSize);
                if (!chunk.length) {
                    break;
                }
                if (isBig) {
                    await queue.put(new index_js_3.Raw.upload.SaveBigFilePart({
                        fileId: fileId,
                        filePart: filePart,
                        fileTotalParts: fileTotalParts,
                        bytes: chunk,
                    }));
                }
                else {
                    await queue.put(new index_js_3.Raw.upload.SaveFilePart({
                        fileId: fileId,
                        filePart: filePart,
                        bytes: chunk,
                    }));
                }
                if (isMissingPart) {
                    return;
                }
                filePart += 1;
                if (progress) {
                    progress(Math.min(filePart * partSize, fileSize), fileSize);
                }
            }
        }
        catch (error) {
            Logger_js_1.Logger.error('[136] Got error when trying to put rpc to queue', error);
        }
        finally {
            for (let _ of workers) {
                await queue.put(null);
            }
            await queue.put(null);
            await queue.get();
            await session.stop();
            if (isBig) {
                return new index_js_3.Raw.InputFileBig({
                    id: fileId,
                    parts: fileTotalParts,
                    name: fileName ?? 'file.unknown',
                });
            }
            else {
                return new index_js_3.Raw.InputFile({
                    id: fileId,
                    parts: fileTotalParts,
                    name: fileName ?? 'file.unknown',
                    md5Checksum: md5,
                });
            }
        }
    }
    finally {
        release();
    }
}
exports.upload = upload;
